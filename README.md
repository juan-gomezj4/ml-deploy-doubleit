# TorchScript Model Deployment: DoubleIt API - Streamlit App

# ğŸ”§ DescripciÃ³n del Proyecto

Este repositorio contiene una soluciÃ³n completa para desplegar un modelo TorchScript llamado **DoubleIt**, cuyo objetivo es multiplicar una lista de nÃºmeros por 2

La finalidad principal del reto es **poner en producciÃ³n este modelo** utilizando buenas prÃ¡cticas de ingenierÃ­a, cubriendo los siguientes aspectos clave:

- ContainerizaciÃ³n del modelo y su API
- Pruebas unitarias con cobertura
- AutomatizaciÃ³n del despliegue (`dev`) mediante CI/CD con GitHub Actions
- Infraestructura como cÃ³digo (IaC) con Terraform
- SeparaciÃ³n de entornos (`dev` y `prod`) para facilitar pruebas y despliegues controlados

Se asume que la inferencia se realiza vÃ­a una llamada sÃ­ncrona desde un backend (FastAPI) a un modelo TorchScript, y se expone una interfaz simple mediante Streamlit para facilitar la interacciÃ³n

El modelo ya entrenado se encuentra serializado en formato TorchScript y listo para su consumo

# ğŸ“ Estructura del Repositorio

La siguiente estructura organiza el proyecto en mÃ³dulos funcionales y componentes reutilizables:

```
â”œâ”€â”€ codecov.yml                                     # ConfiguraciÃ³n de cobertura para Codecov
â”‚
â”œâ”€â”€ docker/
â”‚ â”œâ”€â”€ backend/Dockerfile                            # Imagen Docker del backend (FastAPI)
â”‚ â””â”€â”€ frontend/Dockerfile                           # Imagen Docker del frontend (Streamlit)
â”‚
â”œâ”€â”€ docker-compose.yml                              # OrquestaciÃ³n local de backend y frontend
â”‚
â”œâ”€â”€ iac/                                            # Infraestructura como cÃ³digo (Terraform)
â”‚ â”œâ”€â”€ main.tf
â”‚ â”œâ”€â”€ outputs.tf
â”‚ â”œâ”€â”€ terraform.tfvars
â”‚ â””â”€â”€ variables.tf
â”‚
â”œâ”€â”€ infra_setup.sh                                  # Script para automatizar Terraform + GitHub Secret
â”‚
â”œâ”€â”€ Makefile                                        # Comandos utilitarios para test, lint, terraform
â”‚
â”œâ”€â”€ models/                                         # Carpeta con modelo TorchScript
â”‚ â”œâ”€â”€ doubleit_model/                               # RepresentaciÃ³n detallada del modelo
â”‚ â”œâ”€â”€ doubleit_model.pt                             # Modelo TorchScript serializado
â”‚ â”œâ”€â”€ inference_example.py                          # Script para pruebas manuales del modelo
â”‚ â””â”€â”€ rebuild_model.py                              # ReconstrucciÃ³n del modelo desde PyTorch
â”‚
â”œâ”€â”€ pyproject.toml                                  # Metadata del proyecto, dependencias y configuraciÃ³n de herramientas
â”‚
â”œâ”€â”€ README.md                                       # DocumentaciÃ³n del proyecto
â”‚
â”œâ”€â”€ src/                                            # CÃ³digo fuente
â”‚ â”œâ”€â”€ backend/app.py                                # API REST para predicciÃ³n
â”‚ â”œâ”€â”€ frontend/app.py                               # Interfaz Streamlit
â”‚ â”œâ”€â”€ model/
â”‚ â”‚ â”œâ”€â”€ load_model.py                               # LÃ³gica de carga y uso del modelo
â”‚ â”‚ â””â”€â”€ schema.py                                   # ValidaciÃ³n con Pydantic
â”‚ â””â”€â”€ tmp_mock.py                                   # MÃ³dulo de prueba para pre-commit
â”‚
â”œâ”€â”€ tests/                                          # Pruebas unitarias
â”‚ â”œâ”€â”€ test_backend.py
â”‚ â”œâ”€â”€ test_mock.py
â”‚ â””â”€â”€ test_model.py
â”‚
â””â”€â”€ uv.lock                                        # Archivo de dependencias generado por UV
```

# ğŸ“¦ Model Deployment: Componentes Principales

Este proyecto implementa un flujo completo de MLOps para un modelo TorchScript (`doubleit_model.pt`), usando FastAPI como backend de inferencia y Streamlit como interfaz de usuario.

### ğŸ” Backend (FastAPI)
- **UbicaciÃ³n:** `src/backend/app.py`
- **Objetivo:** Proveer un endpoint REST (`/predict`) para inferencia sobre listas de enteros
- **Carga del modelo:** `load_model.py` usa `torch.jit.load` para deserializar el modelo TorchScript
- **ValidaciÃ³n:** `schema.py` valida entradas usando `pydantic`

### ğŸ–¥ï¸ Frontend (Streamlit)
- **UbicaciÃ³n:** `src/frontend/app.py`
- **Objetivo:** Recibir entrada del usuario, llamar al backend y mostrar la predicciÃ³n
- **ComunicaciÃ³n:** HTTP POST al endpoint `/predict` del backend

### ğŸ“¦ Empaquetamiento (Docker)
- **Dockerfiles:** Separados para backend y frontend
- **docker-compose:** Orquesta ambos servicios localmente, expuestos en puertos 8000 y 8501 respectivamente
- **Build multiplataforma:** `--platform linux/amd64` para compatibilidad con Cloud Run

### ğŸŒ Despliegue (Cloud Run)
- **Backend y frontend:** se despliegan como servicios independientes (`doubleit-backend-dev`, `doubleit-frontend-dev`)
- **AutenticaciÃ³n:** pÃºblica (`--allow-unauthenticated`) para facilitar acceso
- **Deploy automatizado:** vÃ­a GitHub Actions

### ğŸ“¦ Modelo TorchScript
- **Archivo principal:** `doubleit_model.pt`
- **ReconstrucciÃ³n:**  en base a la estructura compartida, empleando el script `rebuild_model.py`
- **Inferencia:** Entrada â†’ tensor â†’ salida multiplicada por 2

# ğŸ³ ContainerizaciÃ³n

La soluciÃ³n se empaqueta mediante contenedores Docker separados para el backend y el frontend. Esto garantiza portabilidad, aislamiento y compatibilidad con entornos de ejecuciÃ³n -como Cloud Run-

### ğŸ“ Archivos relevantes

- `docker/backend/Dockerfile`: construye la imagen para el servicio FastAPI
- `docker/frontend/Dockerfile`: construye la imagen para el servicio Streamlit
- `docker-compose.yml`: permite ejecutar ambos servicios localmente con un solo comando

### ğŸ’¡ Detalles tÃ©cnicos

- **Base image:** `python:3.11-slim` (ligera y optimizada)
- **Gestor de dependencias:** `uv` con `pyproject.toml` y `uv.lock`
- **Entrypoints:**
  - Backend: `uvicorn src.backend.app:app`
  - Frontend: `streamlit run src/frontend/app.py`
- **Compatibilidad Cloud Run:** Se utiliza arquitectura `linux/amd64` en CI/CD para asegurar compatibilidad con ambientes x86_64

# ğŸ§ª Pruebas Unitarias y Cobertura

El proyecto incluye pruebas unitarias para validar el comportamiento del modelo y el backend

### ğŸ“ Estructura de pruebas
```
tests/
â”œâ”€â”€ test_backend.py                                 # Pruebas del endpoint FastAPI
â”œâ”€â”€ test_model.py                                   # Pruebas del modelo TorchScript
â”œâ”€â”€ test_mock.py                                    # Prueba para validar CI y pre-commit
```

### âœ… Cobertura

- Se utiliza `pytest` junto con `pytest-cov` para medir la cobertura de cÃ³digo
- Los comandos estÃ¡n integrados en el `Makefile`:
  - `make test`: ejecuta pruebas con cobertura
  - `make test_verbose`: modo detallado
  - `make test_coverage`: genera reporte XML para Codecov

### ğŸ“Š Codecov

El archivo codecov.yml define umbrales mÃ­nimos y tolerancias para garantizar calidad continua

# ğŸŒ Estrategia de Entornos: Dev vs Prod

Aunque el requirimiento no exigÃ­a una implementaciÃ³n real en la nube y aceptaba una propuesta estructural, esta soluciÃ³n fue llevada a producciÃ³n sobre Google Cloud Platform como una demostraciÃ³n prÃ¡ctica de dominio tÃ©cnico y alineaciÃ³n con estÃ¡ndares reales de despliegue en la industria

Se plantea una separaciÃ³n clara entre los entornos `dev` y `prod`, cada uno con responsabilidades bien definidas:

### ğŸ” Entorno `dev` â€” AutomatizaciÃ³n vÃ­a CI/CD

- **Objetivo:** pruebas rÃ¡pidas, validaciÃ³n continua y despliegue inmediato tras cada cambio en el repositorio
- **ImplementaciÃ³n:** GitHub Actions ejecuta el flujo completo de CI/CD, que incluye:
  - InstalaciÃ³n del entorno
  - Linter, formateo y validaciones de estilo (`pre-commit`)
  - Pruebas unitarias y cobertura
  - ConstrucciÃ³n y despliegue de imÃ¡genes Docker a Cloud Run
- **Servicios desplegados:** `doubleit-backend-dev`, `doubleit-frontend-dev`
- **Acceso:** pÃºblico (`--allow-unauthenticated`)
- **ConexiÃ³n:** la URL del backend se pasa como variable de entorno al frontend en tiempo de despliegue

### ğŸ”’ Entorno `prod` â€” Provisionamiento con Terraform

- **Objetivo:** entorno estable y controlado, con posibilidad de configuraciones especÃ­ficas como autenticaciÃ³n, dominios personalizados o escalado avanzado
- **ImplementaciÃ³n:** Terraform permite crear toda la infraestructura necesaria, incluyendo cuentas de servicio, repositorios en Artifact Registry y servicios en Cloud Run
- **Estado actual:** el entorno `prod` no fue desplegado, pero su definiciÃ³n estÃ¡ completamente lista para ejecutarse siguiendo el mismo flujo

### ğŸ§± RelaciÃ³n entre ambos entornos

- Terraform define los **recursos base compartidos**, como el Artifact Registry y la cuenta de servicio que usa GitHub Actions
- GitHub Actions usa estos recursos para desplegar el entorno `dev`
- En un contexto real, Terraform permitirÃ­a extender esta lÃ³gica para crear el entorno `prod`, asegurando separaciÃ³n, versionado y buenas prÃ¡cticas de infraestructura

Esta arquitectura hÃ­brida permite un desarrollo Ã¡gil en `dev` y una base sÃ³lida para un entorno `prod` preparado para escalar

# âš™ï¸ CI/CD con GitHub Actions (Entorno Dev)

El entorno de desarrollo (`dev`) se despliega automÃ¡ticamente mediante un pipeline de GitHub Actions que ejecuta los siguientes pasos:

### ğŸ”„ Flujo CI/CD

1. **CI (IntegraciÃ³n Continua):**
   - **Pre-commit hooks:** validaciÃ³n de estilo con `ruff` y `black`
   - **Pruebas unitarias:** ejecuciÃ³n con `pytest` y generaciÃ³n de reporte de cobertura con `coverage`
   - **Subida de cobertura:** integraciÃ³n con Codecov

2. **CD (Despliegue Continuo):**
   - **AutenticaciÃ³n con GCP:** usando una cuenta de servicio configurada como secreto (`GCP_CREDENTIALS`)
   - **Build de imÃ¡genes Docker:** para backend y frontend, incluyendo arquitectura `linux/amd64` para compatibilidad con Cloud Run
   - **Push a Artifact Registry.**
   - **Despliegue en Cloud Run:** con `--memory=1Gi` y `--allow-unauthenticated`.

### ğŸš€ Jobs del Workflow

```yaml
on:
  push:
    branches: [main]
  pull_request:

jobs:
  lint-and-format:
    ...

  test:
    ...

  build-and-deploy:
    ...
```

### ğŸ§© Variables y secretos utilizados

- GCP_CREDENTIALS: clave JSON de la cuenta de servicio
- GCP_PROJECT_ID: ID del proyecto
- GCP_REGION: regiÃ³n donde se despliega (us-central1)
- BACKED_URL: pasado como variable al frontend para consumo del API

Este flujo garantiza un entorno funcional cada vez que se hace push a main, permitiendo validar en caliente los cambios de backend y frontend sobre GCP

# ğŸ› ï¸ Infraestructura como CÃ³digo (IaC)

La infraestructura base fue definida con Terraform, siguiendo el enfoque de separar los recursos compartidos del despliegue por entorno. El objetivo es centralizar la creaciÃ³n de componentes reutilizables (como cuentas de servicio y repositorios) y habilitar entornos con configuraciones distintas segÃºn sea `dev` o `prod`

### ğŸ“¦ Recursos creados por Terraform

- **`Service Account`**: `github-deployer` con los siguientes roles:
  - `roles/run.admin`
  - `roles/artifactregistry.admin`
  - `roles/cloudbuild.builds.editor`
  - `roles/iam.serviceAccountUser`

- **`Artifact Registry`**:
  - Repositorio Docker: `ml-deploy-repo` en `us-central1`

### ğŸš€ Flujo de uso local

Se automatiza con `Makefile` y un script `infra_setup.sh`:

```bash
bash infra_setup.sh
```

Este script ejecuta:

1. terraform init y terraform apply

2. Crea la clave JSON de la cuenta de servicio

3. Sube la clave como secreto a GitHub (GCP_CREDENTIALS)

4. Elimina la clave local por seguridad

### ğŸ§­ ExtensiÃ³n hacia prod

La misma lÃ³gica permite escalar la infraestructura:

- Crear servicios separados (doubleit-backend-prod, doubleit-frontend-prod)
- Ajustar memoria, seguridad y dominios
- Activar autenticaciÃ³n y polÃ­ticas mÃ¡s estrictas

Aunque en esta prueba solo se desplegÃ³ dev vÃ­a CI/CD, la arquitectura estÃ¡ preparada para soportar mÃºltiples entornos gestionados por Terraform

# ğŸš€ CÃ³mo Ejecutar Localmente

### Pasos:

1. Clonar el repositorio
2. Instalar Docker y Docker Compose
3. Ejecutar `docker-compose up --build` para levantar backend y frontend
4. Acceder al backend en `http://localhost:8000/docs`
5. Acceder al frontend en `http://localhost:8501`
6. Instalar [uv]
7. Ejecutar `uv sync --all-groups` para instalar dependencias
8. Ejecutar pruebas con `make test`


# â˜ï¸ CÃ³mo Desplegar en GCP

### Pasos:

1. Crear un proyecto en GCP (ej. `ml-deploy-doubleit`)
2. Activar las APIs necesarias:
   - Cloud Run
   - Artifact Registry
   - IAM
3. Clonar este repositorio y posicionarse en la raÃ­z del proyecto
4. Crear el archivo `.env` desde `.env.example` con:
   - `PROJECT_ID`
   - `SA_NAME`
   - `REGION`
5. Ejecutar `bash infra_setup.sh` para:
   - Crear la cuenta de servicio `github-deployer`
   - Crear el repositorio `ml-deploy-repo` en Artifact Registry
   - Asignar permisos mÃ­nimos a la cuenta
   - Generar la clave JSON y subirla como secreto en GitHub
6. Verificar que en GitHub existan los secretos:
   - `GCP_CREDENTIALS`
   - `GCP_PROJECT_ID`
   - `GCP_REGION`
7. Hacer `git push` a `main` y dejar que GitHub Actions despliegue automÃ¡ticamente en Cloud Run
8. Consultar las URLs generadas en la consola de Cloud Run (backend y frontend)


# ğŸ“ˆ Consideraciones de Monitoreo, Versionamiento y Seguridad

Se proponen las siguientes prÃ¡cticas adicionales para entornos productivos:

### ğŸ©º Monitoreo
- **Cloud Logging & Monitoring**: Cloud Run exporta logs automÃ¡ticamente a Google Cloud Logging. Se pueden crear alertas en Cloud Monitoring para:
  - Errores HTTP 5xx
  - Fallos en despliegues
  - SuperaciÃ³n de umbrales de memoria/CPU

### ğŸ§¬ Versionamiento de Modelos
- **Artifact Registry** gestiona versiones de imÃ¡genes (`doubleit-backend:1.0.0`, `doubleit-backend:latest`, etc.)
- **Modelo TorchScript** puede versionarse por nombre de archivo y almacenarse en Cloud Storage o Artifact Registry
- Uso de etiquetas y ramas en Git para separar releases (`main`, `prod`, `v1.0`)

### ğŸ” Seguridad
- **MÃ­nimos privilegios**: la cuenta de servicio de CI/CD tiene solo los roles estrictamente necesarios
- **Secretos gestionados en GitHub**: la clave JSON no se sube al repo, se inyecta como secreto
- **Accesos**:
  - El entorno `dev` permite acceso pÃºblico (`--allow-unauthenticated`)
  - El entorno `prod` puede configurarse con autenticaciÃ³n o IP filtering

